\documentclass{article}

\usepackage{enumerate}
\usepackage{amsmath}

\title{Categorical Data Analysis: Homework 3}
\author{Gilbert Watson}
\date{\today}

\begin{document}
\SweaveOpts{concordance=TRUE}

\maketitle

%test

\section*{2.15}

First let's create the tables:

<<table>>=
admissions <- array(data=c(512,313,89,19,
                           353,207,17,8,
                           120,205,202,391,
                           138,279,131,244,
                           53,138,94,299,
                           22,351,24,317),
                    dim=c(2,2,6),
                    dimnames=list(Admitted=c("Yes","No"),
                                  Gender=c("Male","Female"),
                                  Department=c("A","B","C","D","E","F")))
admissions
@

\noindent
Now let's find the Admit/Gender conditional odds ratios:

<<conditionaloddsratios>>=
departments <- unique(dimnames(admissions))[[3]]
condOdds <- sapply(departments,function(x) {
  table <- admissions[,,x]
  odds <- table[1,1]*table[2,2]/(table[1,2]*table[2,1])
  return(odds)
})
condOdds
@

\noindent
And the Admit/Gender marginal odds ratios:

<<marginaloddsratios>>=
mT <- margin.table(admissions,c(1,2))
mT

margOdds <- mT[1,1]*mT[2,2]/(mT[1,2]*mT[2,1])
margOdds
@

The marginal odds ratio indicates that there is a difference between admittance rates for males and females. After conditioning on department, it appears as though the difference becomes negligible, if not favoring women for most departments. The difference is likely due to the large number of admits into departments C and E. Though the conditional odds ratio for these departments is not very far away from 1, if these were large departments, the number of males overall would get very large compared to females.

\section*{2.32}

Equal $\theta{}_{XY|Z}$ marginal odds ratios would be defined by the following identity:

$$ \frac{n_{111}n_{221}}{n_{121}n_{211}} = \frac{n_{112}n_{222}}{n_{122}n_{212}} $$

\noindent
cross multiplying terms from the left hand numerator and the right hand denominator:

$$ \frac{n_{111}n_{122}}{n_{121}n_{211}} = \frac{n_{112}n_{222}}{n_{212}n_{221}} $$

\noindent
cross multiplying terms from the left hand denominator and the right hand numerator:

$$ \frac{n_{111}n_{122}}{n_{112}n_{121}} = \frac{n_{211}n_{222}}{n_{212}n_{221}} $$

\noindent
which is the identity for equal $\theta{}_{YZ|X}$ marginal odds ratios.


\section*{3.16}

First, let's make the table:

<<table2>>=
aspirations <- data.frame(Low=c(9,44,13,10),
                          Middle=c(11,52,23,22),
                          High=c(9,41,12,27),
                          row.names=c("Some High School",
                                      "High School Graduate",
                                      "Some College",
                                      "College Graduate"))
aspirations
@

\begin{enumerate}[a.]

\item{} First let's find the $\chi{}^2$ statistic:

<<chisquare>>=
ChiSqr <- chisq.test(aspirations,correct=F)
ChiSqr
@

Now let's find the $G^2$ statistic:

<<gsquared>>=
G2 <- function(table) {
  C2 <- chisq.test(table,correct=F)
  obs <- C2$observed
  exp <- C2$expected
  G2 <- 2*sum(obs*log(obs/exp))
  pvalue <- 1 - pchisq(G2,df=C2$parameter["df"])
  return(list(G_Squared=G2,p_value=pvalue))
}
GSqr <- G2(aspirations)
GSqr
@

\item Now let's find the standardized residuals:

<<standardizedresiduals>>=
ChiSqr$stdres
@

The standardized residuals suggest that there is a more complex relationship between income and education aspirations. Low income students aspire to lower levels of education that is expected, while high income students aspire to higher levels of education than is expected. Most importantly, the standardized residual for high income students aspiring to graduation college is greater than 2, indicating a lack of fit.

\item A test using the ordinal nature of the row and columns may be more powerful. Let's give income and aspiration level ordinal values and see.

<<partitionedtable>>=
require(reshape2)
require(plyr)
dat <- melt(aspirations)
dat$aspiration <- c(rep(row.names(aspirations),3))
dat <- rbind.fill(apply(dat,1,function(x) {
  n <- as.numeric(x[2])
  out <- data.frame(Income=rep(x[1],n),Aspiration=rep(x[3],n))
  return(out)
}))
dat$Income <- as.numeric(dat$Income)
dat$Aspiration <- as.numeric(dat$Aspiration)
# find M^2
r <- cor(dat$Income,dat$Aspiration)
M2 <- c(M2 = r^2*(sum(aspirations) - 1))
pvalueM2 <- c(pvalue_M2=1 - pchisq(M2, 1))
M2
pvalueM2
@

This test indicates that there is a statistically significant association between income and education aspiration.


\end{enumerate}

\section*{11.3}

First let's create the table:

<<belief>>=
belief = data.frame(Hell.Yes=c(955,9),Hell.No=c(162,188),
                    row.names=c("Heaven.Yes","Heaven.No"))
@

\begin{enumerate}[a.]

\item First let's test the marginal proportions:

<<maginalprops>>=
chisq.test(belief,correct=F)
@

Clearly, using the $\chi{}^2$ statistic for marginal proportions, we reject the null hypothesis of independence in proportions.

\item Now let's perform McNemar's test:

<<mcnemar>>=
mcnemar.test(as.matrix(belief),correct=F)
@

This test also suggests that we reject the null hypothesis of independence of belief in hell and belief in heaven.

\item Both these test indicate that we should reject the null hypothesis of independence in favor of the conclusion that there is a depend relationship between beliefs. This design is more precise because the variance of the test statistic is lower for dependent sample designs.

\end{enumerate}


\section*{11.7}

The data:

<<thedataagain>>=
cancer <- array(0,dim=c(2,2,8),
                dimnames=list(Patient=c("Case","Control"),
                              Meat=c("High","Low"),
                              ID=1:8))
for(i in 1:3) cancer[,1,i]=1
for(i in 4) cancer[,2,i]=1
for(i in 5:7) cancer[1,1,i]=cancer[2,2,i]=1
for(i in 8) cancer[1,2,i]=cancer[2,1,i]=1
@

\begin{enumerate}[a.]

\item Let's create and display tables A and B:

<<tablesAB>>=
A <- array(c(3,1,3,1),dim=c(2,2),
           dimnames=list(Case=c("High","Low"),
                         Control=c("High","Low")))
B <- cancer

A
B
@

\item Now let's calculate the McNemar $z^2$:

<<zsquared>>=
zsquared <- function(table) {
  upper <- sum(table[upper.tri(table)])
  lower <- sum(table[lower.tri(table)])
  z2 <- (upper - lower)^2/(upper + lower)
  pvalue <- 1 - pchisq(z2,1)
  return(list(zsquared=z2,pvalue=pvalue))
}
zsquared(A)
@

and the MCH for table B:

<<mch>>=
mantelhaen.test(B,correct=F)
@

Both statistics are the same.

\item $n_{12}/n_{21}$ for table A is $3/1 = 3$ which is also the CMH odds ratio from above.

\item Let's create a new table with pairs of the same diet deleted and re-calculate all the statistics:

<<newtable>>=
B2 <- B[,,5:8]
mantelhaen.test(B2,correct=F)
@

Clearly the odds ratio and the test statistic stays the same.

\item Now let's conduct an exact test using the binomial distribution. We know the odds ratio is 3 for McNemar's test. Under the null the odds ratio would be $0.5$. So, we can think of the two off diagonals as being distributed binomial with parameters (sum of the off diagonals) and 0.5.

<<fischer>>=
exact_pvalue <- 1 - pbinom(q=3,prob=0.5,size=4)
exact_pvalue
@

\end{enumerate}


\section*{11.15}

<<dataitup>>=
table <- matrix(c(5,15,0,0,0,5,15,0,0,0,5,15,15,0,0,5),
                nrow=4,ncol=4,byrow=T)
table 
@

Now let's calculate kappa:

<<kappa>>=
kappa <- function(table) {
  pitable <- prop.table(table)
  colFreqs <- colSums(pitable)
  rowFreqs <- rowSums(pitable)
  firstsum <- sum(diag(pitable))
  secondsum <- crossprod(colFreqs,rowFreqs)
  Kappa <- (firstsum - secondsum)/(1 - secondsum)
  return(c(Kappa))
}

kappa(table)
@

So the value of $\kappa$ is 0. However, a measure of association, the $\chi{}^2$ statistic for the table is quite high ($\Sexpr{round(chisq.test(table,correct=F)$statistic,digits=4)}$), indicating association. There is association without agreement because, despite the low number of exact agreements, a very clear pattern emerges in the table in the way the columns and rows disagree.

\end{document}
